# S3 general purpose buckets should log object-level write events

# Imports

import "tfplan/v2" as tfplan
import "tfresources" as tf
import "report" as report
import "collection" as collection
import "collection/maps" as maps

# Constants

const = {
	"policy_name":               "s3-log-object-level-write-events",
	"message":                   "S3 general purpose buckets should log object-level write events. At least one multi-region CloudTrail trail must log all write data events for S3 buckets. Refer to https://docs.aws.amazon.com/securityhub/latest/userguide/s3-controls.html#s3-22 for more details.",
	"resource_aws_cloudtrail":   "aws_cloudtrail",
	"is_multi_region_trail":     "is_multi_region_trail",
	"event_selector":            "event_selector",
	"read_write_type":           "read_write_type",
	"include_management_events": "include_management_events",
	"data_resource":             "data_resource",
	"type":                      "type",
	"values":                    "values",
	"valid_read_write_types":    ["WriteOnly", "All"],
	"s3_object_type":            "AWS::S3::Object",
	"all_s3_buckets_arn":        "arn:aws:s3:::*/*",
}

# Functions

# Function to check if CloudTrail has valid S3 write event logging configuration
is_cloudtrail_compliant = func(res) {
	# Check if multi-region trail is enabled
	is_multi_region = maps.get(res, "values." + const.is_multi_region_trail, false)
	if is_multi_region is not true {
		return false
	}

	# Check event selectors
	event_selectors = maps.get(res, "values." + const.event_selector, [])
	if event_selectors is null or event_selectors is empty {
		return false
	}

	# Check if at least one event selector has proper S3 write logging configuration
	valid_selector_found = collection.find(event_selectors, func(selector) {
		# Check read_write_type
		read_write_type = maps.get(selector, const.read_write_type, "")
		if read_write_type not in const.valid_read_write_types {
			return false
		}

		# Check data resources
		data_resources = maps.get(selector, const.data_resource, [])
		if data_resources is null or data_resources is empty {
			return false
		}

		# Check if at least one data resource is configured for S3 objects
		valid_data_resource = collection.find(data_resources, func(data_resource) {
			resource_type = maps.get(data_resource, const.type, "")
			resource_values = maps.get(data_resource, const.values, [])

			# Check if type is AWS::S3::Object and values contains all S3 buckets ARN
			return resource_type == const.s3_object_type and
				resource_values is not null and
				resource_values is not empty and
				const.all_s3_buckets_arn in resource_values
		})

		return valid_data_resource is defined
	})

	return valid_selector_found is defined
}

# Variables

cloudtrail_resources = tf.plan(tfplan.planned_values.resources).type(const.resource_aws_cloudtrail).resources

# Check if at least one compliant CloudTrail exists
compliant_trails = collection.reject(cloudtrail_resources, func(res) {
	return is_cloudtrail_compliant(res) is not true
})

# If no CloudTrail resources exist or none are compliant, create violations
violations = []
if cloudtrail_resources is empty or compliant_trails is empty {
	# Create a single violation for the account
	violations = [{
		"address":        "AWS::::Account",
		"module_address": "",
		"message":        const.message,
	}]
}

summary = {
	"policy_name": const.policy_name,
	"violations":  violations,
}

# Outputs

print(report.generate_policy_report(summary))

# Rules

main = rule {
	violations is empty
}
